{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06213b9d",
   "metadata": {},
   "source": [
    "# The module 1 by analytics : task classification image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91442561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8ccacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 300, 300 # Указываем разрешение для изображений к единому формату\n",
    "\n",
    "directory_data_train= 'dir/train' #Указываем путь к обучающей выборке train_data_dir \n",
    "directory_data_validation= 'dir/validation'  #Указываем путь к проверочной выборке validation_data_dir \n",
    "\n",
    "# Сразу устанавливаем необходимые параметры\n",
    "\n",
    "train_sample = 1000\n",
    "validation_sample = 500\n",
    "epochs = 8\n",
    "lot_size = 25  #batch_size \n",
    "if K.image_data_format() != 'channels_first':\n",
    "     input_shape = (image_width, image_height, 3)\n",
    "else:\n",
    "     input_shape = (3, image_width, image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73a61ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = Sequential() # Создание модели\n",
    "\n",
    "# Первый слой нейросети\n",
    "pattern.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "pattern.add(Activation('relu'))\n",
    "pattern.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Второй слой нейросети\n",
    "pattern.add(Conv2D(32, (3, 3)))\n",
    "pattern.add(Activation('relu'))\n",
    "pattern.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Третий слой нейросети\n",
    "pattern.add(Conv2D(64, (3, 3)))\n",
    "pattern.add(Activation('relu'))\n",
    "pattern.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Aктивация, свертка, объединение, исключение\n",
    "pattern.add(Flatten())\n",
    "pattern.add(Dense(64))\n",
    "pattern.add(Activation('relu'))\n",
    "pattern.add(Dropout(0.5))\n",
    "pattern.add(Dense(2))# число классов\n",
    "pattern.add(Activation('softmax'))\n",
    "\n",
    "#Cкомпилируем модель с выбранными параметрами. Также укажем метрику для оценки.\n",
    "pattern.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "515ba2bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2972147360.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_26210/2972147360.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    test_datagen = ImageDataGenerator(rescale=1. / 255)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Задаём параметры аугментации\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255, # коэффициент масштабирования\n",
    "    shear_range=0.2, # Интенсивность сдвига\n",
    "    zoom_range=0.2, # Диапазон случайного увеличения\n",
    "    horizontal_flip=True) # Произвольный поворот по горизонтали\n",
    " test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5815b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Предобработка обучающей выборки cat\n",
    "#  train_processing = train_datagen.flow_from_directory(\n",
    "#     directory_data_train+'/cats',\n",
    "#     target_size=(image_width, image_height), # Размер изображений\n",
    "#     batch_size=lot_size, #Размер пакетов данных\n",
    "#     class_mode='categorical') # Режим класса\n",
    "    \n",
    "# #Предобработка обучающей выборки dog\n",
    "#  train_processing = train_datagen.flow_from_directory(\n",
    "#     directory_data_train+'/dogs',\n",
    "#     target_size=(image_width, image_height), # Размер изображений\n",
    "#     batch_size=lot_size, #Размер пакетов данных\n",
    "#     class_mode='categorical') # Режим класса\n",
    "\n",
    "# #Предобработка тестовой выборки\n",
    "# validation_processing= test_datagen.flow_from_directory(\n",
    "#     directory_data_validation+'/cats',\n",
    "#     target_size=(image_width, image_height),\n",
    "#     batch_size=lot_size,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# #Предобработка тестовой выборки\n",
    "# validation_processing= test_datagen.flow_from_directory(\n",
    "#     directory_data_validation+'/dogs',\n",
    "#     target_size=(image_width, image_height),\n",
    "#     batch_size=lot_size,\n",
    "#     class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c35cb49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26210/1782361965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pattern.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     directory_data_train+'/cats/') # Количество итерации, но на проверочном пакете данных\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pattern.fit(directory_data_train+'/cats/') # Количество итерации, но на проверочном пакете данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "483f682e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7dc7ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lot_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90349e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
